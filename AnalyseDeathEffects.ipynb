{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.preprocessing\n",
    "import sklearn.metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "\n",
    "import voteestimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalysisSetCreator:\n",
    "    \n",
    "    def __init__(self, votesmodel='Meindertsma'):\n",
    "\n",
    "        votesmodels = {'Meindertsma': voteestimator.MeindertsmaVotesEstimator(),\n",
    "                      'Exponential': voteestimator.ExponentialVotesEstimator()\n",
    "                      }\n",
    "        self.votesmodel = votesmodels[votesmodel]\n",
    "    \n",
    "    def _combine_data(self, filefolder):\n",
    "        self.notering = pd.read_parquet(os.path.join(filefolder, 'notering.parquet'))\n",
    "        self.song = pd.read_parquet(os.path.join(filefolder, 'song.parquet'))\n",
    "        self.songartist = pd.read_parquet(os.path.join(filefolder, 'songartist.parquet'))\n",
    "        self.artist = (pd.read_parquet(os.path.join(filefolder, 'artist.parquet')) # TODO: This should not happen here\n",
    "                          .pipe(self._artist_features)\n",
    "                        )\n",
    "        \n",
    "        df = (self.notering.merge(self.song, left_on='SongID', right_index=True)\n",
    "                           .merge(self.songartist.reset_index())\n",
    "                           .merge(self.artist, left_on='ArtistID', right_index=True, suffixes=('Song', 'Artist'))\n",
    "             )\n",
    "        return df\n",
    "    \n",
    "    def _read_stemperiodes(self, path=os.path.join('Data', 'EindeStemperiode.xlsx')):\n",
    "        einde_stemperiode = (pd.read_excel(path, engine='openpyxl')  # openpyxl does support xlsx\n",
    "                               .dropna(subset=['EindeStemperiode'])\n",
    "                               .drop(columns=['Bron'])\n",
    "                               .sort_values('EindeStemperiode')\n",
    "                            )\n",
    "        return einde_stemperiode\n",
    "    \n",
    "\n",
    "    def _check_passed_away_during_top2000(self, df, top2000_stemperiodes):\n",
    "        first_stemperiode = top2000_stemperiodes['EindeStemperiode'].min()\n",
    "        relevant_date_of_death = first_stemperiode + pd.Timedelta('365 days')\n",
    "        df['IsOverleden'] = df['Overlijdensdatum'].ge(relevant_date_of_death)\n",
    "        return df\n",
    "    \n",
    "    def _find_next_top2000_after_death(self, df, top2000_stemperiodes):\n",
    "        not_passed_away_during_top_2000 = df[~df['IsOverleden']].copy()\n",
    "        passed_away_during_top2000 = (df.loc[df['IsOverleden']]\n",
    "                                      .sort_values('Overlijdensdatum')\n",
    "                                      .reset_index()\n",
    "                                     )\n",
    "\n",
    "        passed_away_during_top2000 = (pd.merge_asof(passed_away_during_top2000, top2000_stemperiodes,\n",
    "                                                   left_on='Overlijdensdatum', right_on='EindeStemperiode', direction='forward')\n",
    "                                     .set_index('ArtistID')\n",
    "                                     )\n",
    "        df = pd.concat([not_passed_away_during_top_2000, passed_away_during_top2000], sort=False)\n",
    "        return df\n",
    "\n",
    "\n",
    "    def _artist_features(self, df):\n",
    "        einde_stemperiode = self._read_stemperiodes()\n",
    "        df = (df                                          \n",
    "                .pipe(self._check_passed_away_during_top2000, einde_stemperiode)\n",
    "                .pipe(self._find_next_top2000_after_death, einde_stemperiode)\n",
    "                .assign(AgePassing = lambda df: df['Overlijdensdatum'].sub(df['Geboortedatum']).dt.days / 365.25,\n",
    "                        PassingTooEarly = lambda df: df['AgePassing'].sub(80).mul(-1).clip(lower=0),\n",
    "                        IsDutch = lambda df: df['IsDutch'].astype(int),\n",
    "                        )\n",
    "             )\n",
    "        return df\n",
    "    \n",
    "    def _rank_features(self, df):\n",
    "        return df.assign(PctVotes = lambda df: df['Rank'].apply(self.votesmodel.percentage_of_votes))\n",
    "    \n",
    "    \n",
    "    def _normalize_by_years_before_death(self, df, years_to_normalize=2):        \n",
    "        mi = pd.MultiIndex.from_product([df.query('IsOverleden')['SongID'].unique(),\n",
    "                                         df.query('IsOverleden')['YearsSinceOverlijden'].unique(),],\n",
    "                                        names=['SongID', 'YearsSinceOverlijden'])\n",
    "        votes_before_death = (pd.DataFrame(index=mi)\n",
    "                              .join(self.songartist)\n",
    "                              .join(df.set_index(['SongID', 'YearsSinceOverlijden', 'ArtistID'])[['Year', 'PctVotes']])\n",
    "                              .join(self.artist[['JaarTop2000']])\n",
    "                              .join(self.song[['YearMade']])\n",
    "                              .assign(YearTop2000 = lambda df: df['JaarTop2000'].add(df.index.get_level_values('YearsSinceOverlijden')),\n",
    "                                      PctVotes = lambda df: np.where(df['YearTop2000'].gt(df['YearMade']) & df['YearTop2000'].le(df['Year'].max()),\n",
    "                                                             df['PctVotes'].fillna(self.votesmodel.lower_than_2000), np.nan)\n",
    "                                     )\n",
    "                             ['PctVotes']\n",
    "                             .unstack('YearsSinceOverlijden')\n",
    "                             .loc[:, range(-years_to_normalize, 0)]\n",
    "                             .mean(axis='columns')\n",
    "                             .rename('PctVotesBeforeDeath')\n",
    "                             .reset_index()\n",
    "                             )\n",
    "        \n",
    "        df = df.merge(votes_before_death, how='left')\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def _song_features(self, df):\n",
    "        \n",
    "        df = (df.assign(NrArtists = lambda df: df.groupby(['SongID', 'Year'])['Rank'].transform('count'),\n",
    "                        YearsSinceOverlijden = lambda df: df['Year'].sub(df['JaarTop2000']),\n",
    "                       )\n",
    "                .pipe(self._normalize_by_years_before_death)\n",
    "             )\n",
    "        return df\n",
    "    \n",
    "    def _song_features_after_passing(self, df):\n",
    "        df = (df.assign(NrsBeforeDeath = lambda df: df.groupby('ArtistID')['ArtistID'].transform('count'),\n",
    "                        PopularityWithinArtist = lambda df: df.groupby('ArtistID')['PctVotesBeforeDeath'].apply(lambda v: v.div(v.mean())),\n",
    "                        LogSongPopularityWithinArtist = lambda df: np.log10(df['PopularityWithinArtist']),\n",
    "                        RecencyWithinArtist = lambda df: df.groupby('ArtistID')['YearMade'].apply(lambda v: v.sub(v.min()).div(v.max() - v.min())),\n",
    "                        YearsBeforeDeath = lambda df: df['YearMade'].sub(df['JaarTop2000']),\n",
    "                        Boost = lambda df: df['PctVotes'].div(df['PctVotesBeforeDeath']),\n",
    "                        MultiplePerformers = lambda df: df['NrArtists'].gt(1).astype(int),\n",
    "                        JarenGeleden = lambda df: df['JaarTop2000'].sub(df['JaarTop2000'].max()),\n",
    "                        )\n",
    "             )\n",
    "        return df\n",
    "    \n",
    "    def create_analysis_set(self, filefolder):\n",
    "        df = (self._combine_data(filefolder)\n",
    "                  .pipe(self._rank_features)\n",
    "                  .pipe(self._song_features)\n",
    "                  .query('YearsSinceOverlijden == 0')\n",
    "                  .query(f'PctVotesBeforeDeath > {self.votesmodel.lower_than_2000}')\n",
    "                  .pipe(self._song_features_after_passing)\n",
    "             )\n",
    "        return df\n",
    "    \n",
    "    def create_artist_set(self, filefolder):\n",
    "        df = self.create_analysis_set(filefolder)\n",
    "        df_artist = (df.groupby('ArtistID')\n",
    "                        .agg({'PctVotes': 'sum',\n",
    "                              'PctVotesBeforeDeath': 'sum',\n",
    "                               'YearMade': 'last'\n",
    "                            }\n",
    "                            )\n",
    "                        .join(self.artist[['Name', 'IsDutch', 'AgePassing', 'JaarTop2000', 'Overlijdensdatum', 'EindeStemperiode']])\n",
    "                        .assign(DaysToStemperiode = lambda df: df['Overlijdensdatum'].sub(df['EindeStemperiode']).dt.days,\n",
    "                                YearsSinceLastHit = lambda df: df['JaarTop2000'].sub(df['YearMade']),\n",
    "                                LogPopularity = lambda df: np.log10(df['PctVotesBeforeDeath']),\n",
    "                                LogPopularityNorm = lambda df: df['LogPopularity'].sub(df['LogPopularity'].median()),\n",
    "                                Boost = lambda df: df['PctVotes'].div(df['PctVotesBeforeDeath']),\n",
    "                                LogBoost = lambda df: np.log(df['Boost']),\n",
    "                                )\n",
    "                    )\n",
    "        return df_artist\n",
    "    \n",
    "    def create_full_feature_set(self, filefolder):\n",
    "        df = self.create_analysis_set(filefolder)\n",
    "        df_artist = self.create_artist_set(filefolder)#.pipe(self._artist_features)\n",
    "        full_set = (df.merge(df_artist, left_on='ArtistID', right_index=True, suffixes=('Song', 'Artist'))\n",
    "                      .assign(\n",
    "                              SongRelativeBoost = lambda df: df['BoostSong'].div(df['BoostArtist']),\n",
    "                              LogRelativeBoost = lambda df: np.log2(df['SongRelativeBoost']),\n",
    "                              LogBoost = lambda df: np.log(df['BoostSong']),\n",
    "                             )\n",
    "           )\n",
    "        return full_set\n",
    "\n",
    "a = AnalysisSetCreator()\n",
    "df_song = a.create_analysis_set('Data')\n",
    "df_artist = a.create_artist_set('Data')\n",
    "df = a.create_full_feature_set('Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist['Boost'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list = a._combine_data('Data')\n",
    "print(f\"In its history, the Top 2000 has seen {full_list['SongID'].nunique()} songs and {full_list['ArtistID'].nunique()} artists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_song['Boost'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_new_position(old_position, votesmodel, boost=1.75):\n",
    "    old_votes = votesmodel.percentage_of_votes(old_position)\n",
    "    new_votes = old_votes\n",
    "    new_position = old_position\n",
    "    while new_votes < boost * old_votes and new_position >= 1:\n",
    "        new_position -= 1\n",
    "        new_votes = votesmodel.percentage_of_votes(new_position)\n",
    "    return max(new_position, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positioning = (pd.DataFrame({'OldPosition': range(1, 2001)})\n",
    "               .assign(NewPosition = lambda df: [calculate_new_position(p, a.votesmodel) for p in df['OldPosition']],\n",
    "                      FactorRanking = lambda df: df['NewPosition'] / df['OldPosition']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positioning.plot(x='OldPosition', y='FactorRanking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create analysis set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate analysis\n",
    "* Newsworthyness of artist passing\n",
    "  * Age when passing away\n",
    "  * Dutch nationality\n",
    "  * Popularity\n",
    "  * Year\n",
    "  * Recency of hits\n",
    "* Days to stemperiode\n",
    "\n",
    "* Song\n",
    "  * Popularity within artist\n",
    "  * Recency of song within artist\n",
    "  \n",
    "### Newsworthyness\n",
    "\n",
    "#### Artist age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_trend(df, column, logy=False):\n",
    "    ycolname = 'LogBoost' if logy else 'Boost'\n",
    "    preds = LinearRegression().fit(df[[column]], df[ycolname]).predict(df[[column]])\n",
    "    ax = df.plot(x=column, y=ycolname, kind='scatter', label='Passed away artists', c='grey')\n",
    "    ax.plot(df[column], preds, 'k', label='Trend')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df_artist, 'AgePassing', logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jaar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df_artist, 'JaarTop2000', logy=False)\n",
    "ax.xaxis.set_major_locator(mtick.MaxNLocator(integer=True))\n",
    "ax.set_ylim(None, 6)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "ax.set_frame_on(False)\n",
    "plt.gcf().savefig('YearEffect.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.catplot(x='IsDutch', y='LogBoost', data=df_artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df_artist, 'PctVotes', logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_trend(df_artist, 'LogPopularity', logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = df_artist.assign(Popularity = lambda df: df['LogPopularity'].sub(df['LogPopularity'].median()),\n",
    "                            Boost = lambda df: df['Boost'])\n",
    "\n",
    "preds = LinearRegression().fit(dftest[['Popularity']], dftest['Boost']).predict(dftest[['Popularity']])\n",
    "ax = dftest.plot(x='Popularity', y='Boost', kind='scatter', c='grey', ylim=(None, 6))\n",
    "ax.plot(dftest[['Popularity']], preds, 'k', label='trend')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.gcf().savefig('PopularityEffect.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df_artist.query('DaysToStemperiode > -365'), 'DaysToStemperiode', logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recency_buckets = (pd.cut(df_artist['DaysToStemperiode'].clip(lower=-365), 6, labels=False, retbins=False, right=False)\n",
    "                  .map({i: v for i, v in enumerate(range(-333, 0, 60))}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist.groupby(recency_buckets)['LogBoost'].agg(['mean', 'sem', 'std', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_artist.groupby(recency_buckets)['LogBoost'].agg(['mean', 'sem', 'std', 'count']).plot(y='mean', yerr='sem')\n",
    "plt.xlim(-365, 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency of last hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df_artist, 'YearsSinceLastHit', logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solo song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['NrArtists'])['LogBoost'].agg(['mean', 'std', 'sem', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['MultiplePerformers'])['LogBoost'].agg(['mean', 'std', 'sem', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity within artist oeuvre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df, 'PopularityWithinArtist', logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df, 'LogSongPopularityWithinArtist', logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency within artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df.query('NrsBeforeDeath > 2'), 'RecencyWithinArtist', logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waterfall(data, color=None, buildup=False, **kwargs):\n",
    "    '''\n",
    "    Plot a buildup or builddown waterfall chart from data\n",
    "    This function was adapted from https://pbpython.com/waterfall-chart.html\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: pd.Series to be shown as waterfall\n",
    "    color: optionally give color as a list for each bar (to highlight some bars)\n",
    "    buildup: False (default) for builddown, True for buildup\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ax: Axis object\n",
    "    data: the data, including a \"total\"-row\n",
    "    blank: the size of the blank space before each bar\n",
    "    '''\n",
    "    #TODO: add connecting lines\n",
    "    if color is None:\n",
    "        color = ['lightgray'] * len(data)\n",
    "\n",
    "    blank = data.cumsum().shift(1).fillna(0)\n",
    "    total = data.sum()\n",
    "    data.loc['Total'] = total\n",
    "    blank.loc['Total'] = 0\n",
    "    color = color + ['gray']\n",
    "    \n",
    "    step = blank.reset_index(drop=True).repeat(3).shift(-1)\n",
    "    step[1::3] = np.nan\n",
    "    \n",
    "    if buildup:\n",
    "        data = data[::-1]\n",
    "        blank = blank[::-1]\n",
    "        color = color[::-1]\n",
    "\n",
    "    ax = data.plot(kind='barh', stacked=True, left=blank, color=color, **kwargs)\n",
    "#     ax.plot(step.values, step.index, 'k--')\n",
    "\n",
    "    return ax, data, blank\n",
    "\n",
    "data = pd.cut(df_artist['Boost'], [0, 1, 1.5, 2.5, np.inf],\n",
    "               labels=['No boost',\n",
    "                       'Up to 50% more votes',\n",
    "                       '1.5 - 2.5 x\\nas many votes',\n",
    "                       'More than 2.5\\nx as many votes']).value_counts(normalize=True).sort_index(ascending=False)\n",
    "data.index = data.index.astype(str)\n",
    "ax, _, _ = plot_waterfall(data, color=['purple', 'purple', 'purple', 'lightgrey'])\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1))\n",
    "ax.set_frame_on(False)\n",
    "plt.tight_layout()\n",
    "plt.gcf().savefig('BoostDistribution.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist.nlargest(10, 'Boost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist['Boost'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "def model_factory(X, y):\n",
    "    passed_away_artists = X['ArtistID'].unique()\n",
    "    artist_lookup = dict(zip(passed_away_artists, range(len(passed_away_artists))))\n",
    "    artist_vals = X['ArtistID'].replace(artist_lookup).values\n",
    "    artist_model = (X.assign(ArtistIDModel = lambda df: X['ArtistID'].map(artist_lookup),\n",
    "                             )\n",
    "                .sort_values('ArtistIDModel')\n",
    "                .drop_duplicates(['ArtistIDModel'])\n",
    "               )\n",
    "    \n",
    "    \n",
    "    coords = {\"obs_id\": np.arange(X.shape[0]),\n",
    "              'Artist': range(len(passed_away_artists))\n",
    "         }\n",
    "    with pm.Model(coords=coords) as model:\n",
    "        artist_idx = pm.Data(\"artist_idx\", artist_vals, dims=\"obs_id\")\n",
    "        days_to_stemperiode = pm.Data('days_to_stemperiode', artist_model['DaysToStemperiode'], dims='Artist')\n",
    "        logpopularity = pm.Data('logpopularity', artist_model['LogPopularityNorm'], dims='Artist')\n",
    "        jaren_geleden = pm.Data(\"jaren_geleden\", artist_model['JarenGeleden'], dims='Artist')\n",
    "        passing_too_early = pm.Data('passing_too_early', artist_model['PassingTooEarly'], dims='Artist')\n",
    "        is_dutch = pm.Data('is_dutch', artist_model['IsDutchArtist'], dims='Artist')\n",
    "\n",
    "        multiple_performers = pm.Data('multiple_performers', X['MultiplePerformers'], dims=\"obs_id\")\n",
    "        popularity_within_oeuvre = pm.Data('popularity_within_oeuvre', X['LogSongPopularityWithinArtist'], dims=\"obs_id\")\n",
    "\n",
    "        # Hyperpriors:\n",
    "        a = pm.Normal(\"a\", mu=0, sigma=2.0)\n",
    "        sigma_a = pm.Exponential(\"sigma_a\", 1.0)\n",
    "\n",
    "        recency_effect_exponent = pm.Normal('recency_effect_exponent', mu=-1.5,sigma=1)\n",
    "        max_recency_effect = pm.Normal('max_recency_effect', mu=2, sigma=2)\n",
    "        effect_popularity = pm.Normal('effect_popularity', mu=0, sigma=2)\n",
    "        history_effect = pm.Normal('history_effect', mu=0, sigma=1)\n",
    "        age_passing_effect = pm.Normal('age_passing_effect', mu=0, sigma=1)\n",
    "        is_dutch_effect = pm.Normal('is_dutch_effect', mu=0, sigma=2)\n",
    "\n",
    "        # Expected value per artist:\n",
    "        mu_artist = (a\n",
    "                     + logpopularity * effect_popularity\n",
    "                     # The correction of subtracting the minimum value is important for two reasons:\n",
    "                     # 1. Since it fixes the minimum value at 1, it breaks the degeneracy with _a_, which makes sampling much more stable\n",
    "                     # 2. It allows for much easier interpretation\n",
    "                     + (np.exp(10**recency_effect_exponent * days_to_stemperiode)- np.exp(10**recency_effect_exponent * -365))* max_recency_effect\n",
    "                     + jaren_geleden * history_effect\n",
    "                     + passing_too_early * age_passing_effect\n",
    "                     + is_dutch * is_dutch_effect\n",
    "                    )\n",
    "\n",
    "        # This is the non-centered version of the model for a much more stable sampling\n",
    "        # See https://twiecki.io/blog/2017/02/08/bayesian-hierchical-non-centered/ for more information\n",
    "        mu_artist = pm.Deterministic(\"mu_artist\", mu_artist, dims=\"Artist\")\n",
    "        za_artist = pm.Normal(\"za_artist\", mu=0.0, sigma=1.0, dims='Artist')\n",
    "        a_artist = pm.Deterministic(\"a_artist\", mu_artist + za_artist * sigma_a, dims=\"Artist\")\n",
    "        sharing_effect = pm.Normal('sharing_effect', mu=0, sigma=2.0)\n",
    "        within_oeuvre_effect = pm.Normal('within_oeuvre_effect', mu=0, sigma=2.0)\n",
    "        theta = (a_artist[artist_idx]\n",
    "                 + multiple_performers * sharing_effect\n",
    "                 + popularity_within_oeuvre * within_oeuvre_effect\n",
    "                )\n",
    "        # Model error:\n",
    "        sigma = pm.Exponential(\"sigma\", 1.0)\n",
    "\n",
    "        y_like = pm.Normal(\"y_like\", theta, sigma=sigma, observed=y, dims=\"obs_id\")\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_factory(X=df.drop(columns='LogBoost'),\n",
    "                   y=df['LogBoost'],\n",
    "                   ) as multilevel_noncentered_model:\n",
    "    display(pm.model_to_graphviz(multilevel_noncentered_model))\n",
    "    multilevel_noncentered_model_idata = pm.sample(10000, tune=2000, return_inferencedata=True, random_seed=RANDOM_SEED, target_accept=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pm.Model(coords=coords) as unpooled_model:\n",
    "#     jaren_geleden = pm.Data(\"jaren_geleden\", df['JarenGeleden'], dims='obs_id')\n",
    "#     logpopularity = pm.Data('logpopularity', df['LogPopularityNorm'], dims='obs_id')\n",
    "#     days_to_stemperiode = pm.Data('days_to_stemperiode', df['DaysToStemperiode'], dims='obs_id')\n",
    "#     age_passing = pm.Data('age_passing', df['AgePassingArtist'], dims='obs_id')\n",
    "    \n",
    "#     multiple_performers = pm.Data('multiple_performers', df['MultiplePerformers'], dims=\"obs_id\")\n",
    "#     popularity_within_oeuvre = pm.Data('popularity_within_oeuvre', df['LogSongPopularityWithinArtist'], dims=\"obs_id\")\n",
    "    \n",
    "#     # Hyperpriors:\n",
    "#     a = pm.Normal(\"a\", mu=0, sigma=10.0)\n",
    "#     recency_effect_exponent = pm.Normal('recency_effect_exponent', mu=-1.5,sigma=1)\n",
    "#     max_recency_effect = pm.Normal('max_recency_effect', 2, )\n",
    "#     effect_popularity = pm.Normal('effect_popularity', mu=0, sigma=10)\n",
    "#     history_effect = pm.Normal('history_effect', mu=0, sigma=10)\n",
    "#     age_passing_effect = pm.Normal('age_passing_effect', mu=0, sigma=10)\n",
    "    \n",
    "#     # Expected value per artist:\n",
    "#     mu_artist = (a\n",
    "#                  + effect_popularity * logpopularity\n",
    "#                  + np.exp(10**recency_effect_exponent * days_to_stemperiode) * max_recency_effect\n",
    "#                  + jaren_geleden * history_effect\n",
    "#                  + age_passing * age_passing_effect\n",
    "#                 )\n",
    "    \n",
    "#     sharing_effect = pm.Normal('sharing_effect', mu=0, sigma=10.0)\n",
    "#     within_oeuvre_effect = pm.Normal('within_oeuvre_effect', mu=0, sigma=10.0)\n",
    "#     theta = (mu_artist\n",
    "#              + multiple_performers * sharing_effect\n",
    "#              + within_oeuvre_effect * popularity_within_oeuvre\n",
    "#             )\n",
    "#     # Model error:\n",
    "#     sigma = pm.Exponential(\"sigma\", 1.0)\n",
    "\n",
    "#     y = pm.Normal(\"y\", theta, sigma=sigma, observed=df['LogBoost'], dims=\"obs_id\")\n",
    "# pm.model_to_graphviz(unpooled_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM_SEED = 42\n",
    "# with unpooled_model:\n",
    "#     unpooled_model_idata = pm.sample(5000, tune=3000, return_inferencedata=True, random_seed=RANDOM_SEED, target_accept=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(multilevel_noncentered_model_idata, var_names=['~za_artist', '~a_artist', '~mu_artist'], round_to=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.rcParams['plot.max_subplots'] = 100  # Since we have many parameters, the number of subplots is larger than the default - allow az to take more time plotting\n",
    "var_names = [\n",
    "            '~a_artist',\n",
    "            '~sigma_a',\n",
    "            '~sigma',\n",
    "            '~za_artist',\n",
    "            '~mu_artist'\n",
    "            ]\n",
    "_ = pm.pairplot(multilevel_noncentered_model_idata,\n",
    "                var_names=var_names, marginals=True,\n",
    "                divergences=True, kind=['scatter', 'kde'],\n",
    "                figsize=(30, 30), scatter_kwargs={'alpha': 0.06})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = az.plot_trace(multilevel_noncentered_model_idata, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_autocorr(multilevel_noncentered_model_idata, var_names=var_names, combined=True, max_lag=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlations(df):\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax = sns.heatmap(df.corr(), cmap='RdBu_r', vmin=-0.8, vmax=0.8, annot=True, fmt='.1%', ax=ax, cbar=False)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = multilevel_noncentered_model_idata.posterior.to_dataframe().droplevel('Artist').loc[lambda x: ~x.index.duplicated()]\n",
    "plot_correlations(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "multilevel_noncentered_model_idata.posterior = multilevel_noncentered_model_idata.posterior.assign_coords({\"N_artist\": (\"Artist\", artist_model['NrsBeforeDeath'])})\n",
    "# plot means\n",
    "multilevel_noncentered_model_idata.posterior.mean(dim=(\"chain\", \"draw\")).plot.scatter(\n",
    "    x=\"N_artist\", y=\"a_artist\", ax=ax, alpha=0.9\n",
    ")\n",
    "ax.axhline(\n",
    "    multilevel_noncentered_model_idata.posterior['a'].median(),\n",
    "    alpha=0.4,\n",
    "    ls=\"--\",\n",
    "    label=\"Est. population mean\",\n",
    ")\n",
    "\n",
    "# plot hdi\n",
    "hdi = az.hdi(multilevel_noncentered_model_idata)['a_artist']\n",
    "ax.vlines(artist_model['NrsBeforeDeath'], hdi.sel(hdi=\"lower\"), hdi.sel(hdi=\"higher\"), color=\"orange\", alpha=0.5)\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"Nr songs in Top 2000 by artist before death\",\n",
    "    ylabel=\"Artist boost\",\n",
    ")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with train_model:\n",
    "    ppc = pm.fast_sample_posterior_predictive(multilevel_noncentered_model_idata)\n",
    "\n",
    "with train_model:\n",
    "    ppc_no_artist = pm.fast_sample_posterior_predictive(multilevel_noncentered_model_idata.posterior.drop_vars(['mu_artist', 'a_artist', 'za_artist']))\n",
    "predictions = pd.DataFrame(ppc['y_like'].T, index=df.index)\n",
    "predictions_no_artist = pd.DataFrame(ppc_no_artist['y_like'].T, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE!! It only works with at least 2 different artists (which is far from perfect... but it is what it is)\n",
    "df_new_data = df.tail(2).copy()\n",
    "df_new_data['JarenGeleden'] = 100\n",
    "\n",
    "# Second comes the hold out data posterior predictive\n",
    "with model_factory(X=df_new_data,\n",
    "                   y=df_new_data['LogBoost'],\n",
    "                   ) as test_model:\n",
    "    # For newly passed artists, we do not know what za_artist should be\n",
    "    ppc = pm.fast_sample_posterior_predictive(multilevel_noncentered_model_idata.posterior.drop_vars(['mu_artist', 'a_artist', 'za_artist']),\n",
    "                                         var_names=['y_like'],\n",
    "                                        )\n",
    "#     plt.figure()\n",
    "#     plt.hist(ppc['y_like'], 30)\n",
    "#     plt.axvline(new_site_Y, linestyle='--', color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the recency effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = {}\n",
    "days = np.arange(-365, 0)\n",
    "for i, row in parameters.iterrows():\n",
    "\n",
    "    recencyeffect = (np.exp(10**row['recency_effect_exponent'] * days) - np.exp(10**row['recency_effect_exponent'] * -365))* row['max_recency_effect']\n",
    "    outcomes[i] = recencyeffect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recencyeffect = pd.DataFrame(outcomes, index=np.arange(-365, 0)).apply(np.exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Every column contains one parameter set\n",
    "ax = df_recencyeffect.sample(1500, axis='columns').plot(c='grey', alpha=0.01, legend=False)\n",
    "ax = df_recencyeffect.median(axis='columns').plot(ax=ax, lw=3, c='darkblue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_recencyeffect.median(axis='columns').plot(lw=3, c='darkblue', label='Estimated effect')\n",
    "(df_artist.assign(RecencyEffect = lambda df: df['Boost']/df['Boost'].median())\n",
    "          .plot(x='DaysToStemperiode', y='RecencyEffect', kind='scatter', ax=ax, c='grey', label='Passed away artists')\n",
    ")\n",
    "ax.set_xlabel('Days until end of voting')\n",
    "ax.set_ylabel('Extra boost')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.gcf().savefig('RecencyEffect.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_to_use = [-365,\n",
    "               *list(range(-350, -50, 50)),\n",
    "               *list(range(-70, -10, 7)),\n",
    "               *list(range(-10, 0, 2))\n",
    "              ]\n",
    "df_recencyeffect.quantile([0.025, 0.16, 0.5, 0.84, 0.975], axis='columns').loc[:, days_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding prediction quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_agg = (pd.concat([predictions.quantile([0.16, 0.5, 0.84], axis='columns').transpose(), df['LogBoost']], axis='columns')\n",
    "                   .rename(columns={0.5: 'yhat'})\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ax = predictions_agg.plot(x='yhat', y='LogBoost', kind='scatter')\n",
    "valmin, valmax = predictions_agg[['LogBoost', 'yhat']].min().min(), predictions_agg[['LogBoost', 'yhat']].max().max()\n",
    "ax.plot([valmin, valmax], [valmin, valmax], 'k--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_exp = predictions_agg.apply(np.exp).rename(columns={'LogBoost': 'Boost'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(predictions_exp['yhat'], predictions_exp['Boost'],\n",
    "             xerr=[predictions_exp['yhat'].sub(predictions_exp[0.16]), predictions_exp[0.84].sub(predictions_exp['yhat'])],\n",
    "             ls=' ', marker='o', alpha=0.2, ms=4)\n",
    "plt.plot([0, 8], [0, 8], 'k--')\n",
    "plt.ylabel('Boost')\n",
    "plt.xlabel('Predicted boost')\n",
    "plt.show()\n",
    "\n",
    "plt.errorbar(predictions_exp['yhat'], predictions_exp['Boost'],\n",
    "             xerr=[predictions_exp['yhat'].sub(predictions_exp[0.16]), predictions_exp[0.84].sub(predictions_exp['yhat'])],\n",
    "             ls=' ', marker='o', alpha=0.2, ms=4)\n",
    "plt.plot([0, 8], [0, 8], 'k--')\n",
    "plt.ylabel('Boost')\n",
    "plt.xlabel('Predicted boost')\n",
    "plt.ylim(0, 8)\n",
    "plt.xlim(0, 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = (df\n",
    "              .assign(yhat = predictions.median(axis='columns'),\n",
    "                     error = lambda df: df['yhat'].sub(df['LogBoost']),\n",
    "                     abserror = lambda df: df['error'].abs(),\n",
    "                     yhat_no_artist = predictions_no_artist.median(axis='columns'),\n",
    "                     error_without_artisteffect = lambda df: df['yhat_no_artist'].sub(df['LogBoost']),\n",
    "                     abserror_without_artisteffect = lambda df: df['error_without_artisteffect'].abs(),\n",
    "                      improvement_artisteffect = lambda df: df['abserror_without_artisteffect'].sub(df['abserror']),\n",
    "                      yhat_median_params = lambda df: np.log(df.index.map(lambda x: b.all_effects(x)['EffectSize'].prod())),\n",
    "                      error_median_params = lambda df: df['yhat_median_params'].sub(df['LogBoost']),\n",
    "                      abserror_median_params = lambda df: df['error_median_params'].abs(),\n",
    "                     )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior['improvement_artisteffect'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior[['LogBoost', 'yhat', 'yhat_no_artist', 'yhat_median_params']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior['LogBoost'].sub(posterior['LogBoost'].median()).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior['abserror'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior['abserror_without_artisteffect'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior['abserror_median_params'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior['abserror_median_params'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior['error_without_artisteffect'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior.nlargest(10, 'abserror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlations(posterior.filter(variables + ['yhat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_outcomes.nlargest(25, 'ArtistEffect')[['NameArtist', 'ArtistEffect']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_outcomes.nsmallest(5, 'ArtistEffect')[['NameArtist', 'ArtistEffect']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding representative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "             'DaysEffect',\n",
    "            'LogPopularityNorm',\n",
    "            'JarenGeleden',\n",
    "            'MultiplePerformers',\n",
    "            'LogSongPopularityWithinArtist',\n",
    "            'PassingTooEarly',\n",
    "            'IsDutchArtist',\n",
    "             'LogBoost']\n",
    "mm = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "all_data = (posterior\n",
    "            .assign(DaysEffect = lambda df: np.exp(0.007 * df['DaysToStemperiode']))\n",
    "            .filter(variables)\n",
    "            )\n",
    "mm.fit(all_data)\n",
    "\n",
    "data = (posterior\n",
    "        .query('abserror_median_params < 0.15 & JarenGeleden > -19 & LogPopularityNorm > -0.3 ')\n",
    "        .assign(DaysEffect = lambda df: np.exp(0.007 * df['DaysToStemperiode']))\n",
    "        .filter(variables)\n",
    "       )\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = mm.transform(data)\n",
    "dists = sklearn.metrics.pairwise_distances(normalized_data, metric='manhattan')\n",
    "inds = np.argsort(dists, axis=None)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_effects = ['LogBoost', 'yhat', 'error','yhat_no_artist', 'error_without_artisteffect']\n",
    "variables = [v for v in variables if v != 'DaysEffect']\n",
    "for ind in inds[:10:2]:\n",
    "    \n",
    "    x, y = divmod(ind, len(data))\n",
    "    print(f'Distance: {dists[x, y]:.3f}')\n",
    "    ind = data.iloc[[x, y]].index\n",
    "\n",
    "    new_df = pd.concat([df[['NameSong', 'Title', 'LogBoost', 'BoostSong', 'DaysToStemperiode'] + variables], posterior[boosting_effects]], axis='columns')\n",
    "    display(new_df.loc[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figuring out the boost for two songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose to compare Avicii's Hey Brother with Syreeta's With You I Am Born Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoostExplainer:\n",
    "    \n",
    "    def __init__(self, parameters, df):\n",
    "        self.parameters = parameters\n",
    "        self.df = df\n",
    "        \n",
    "    def _get_song(self, song):\n",
    "        if isinstance(song, str):\n",
    "            song = self.df.query(f'Title == \"{song}\"').squeeze()\n",
    "        elif isinstance(song, int):\n",
    "            song = self.df.loc[song]\n",
    "        else:\n",
    "            raise TypeError(f'`song` must be str or int, not {type(song)} ')\n",
    "        return song\n",
    "    \n",
    "    def _calculate_artist_effect(self, song):\n",
    "        base_boost = np.exp(self.parameters['a'])\n",
    "        history_effect = np.exp(self.parameters['history_effect'] * song['JarenGeleden'] )\n",
    "        recency_effect = np.exp((np.exp(10**self.parameters['recency_effect_exponent'] * song['DaysToStemperiode'])\n",
    "                                 - np.exp(10**self.parameters['recency_effect_exponent'] * -365))\n",
    "                                * self.parameters['max_recency_effect'])\n",
    "        popularity_effect = np.exp(self.parameters['effect_popularity'] * song['LogPopularityNorm'])\n",
    "        dutch_effect = np.exp(self.parameters['is_dutch_effect'] * song['IsDutchArtist'])\n",
    "        age_effect = np.exp(self.parameters['age_passing_effect'] * song['PassingTooEarly'])\n",
    "        effects = {\n",
    "                    'Base': base_boost,\n",
    "                    'History': history_effect,\n",
    "                    'Popularity': popularity_effect,\n",
    "                    'Dutch': dutch_effect,\n",
    "                    'PassingTooEarly': age_effect,\n",
    "                    'Recency': recency_effect,\n",
    "                    }\n",
    "        return effects\n",
    "    \n",
    "    \n",
    "    def all_effects(self, song):\n",
    "        song = self._get_song(song)\n",
    "        effects_artist = self._calculate_artist_effect(song)\n",
    "        effects_song = self._calculate_song_effects(song)\n",
    "        effects = (pd.concat([pd.concat({'Artist': pd.Series(effects_artist)}),\n",
    "                            pd.concat({'Song': pd.Series(effects_song)})])\n",
    "                   .rename('EffectSize')\n",
    "                  .to_frame()\n",
    "                  .assign(TotalEffect = lambda df: df['EffectSize'].cumprod())\n",
    "                  )\n",
    "#         effects = pd.DataFrame.from_dict()\n",
    "        return effects\n",
    "    \n",
    "    def _calculate_song_effects(self, song):\n",
    "        oeuvre_effect = np.exp(self.parameters['within_oeuvre_effect'] * song['LogSongPopularityWithinArtist'])\n",
    "        sharing_effect = np.exp(self.parameters['sharing_effect'] * song['MultiplePerformers'])\n",
    "        effects = {\n",
    "                    'WithinOeuvrePopularity': oeuvre_effect,\n",
    "                    'MultiplePerformers': sharing_effect\n",
    "                    }\n",
    "        return effects\n",
    "    \n",
    "    def _print_effects(self, effects, starting_point=1):\n",
    "        effect = starting_point\n",
    "        for name, size in effects.items():\n",
    "            effect *= size\n",
    "            print(f'The effect is {effect:.2f} after {name} - distinct effect: {size:.2f}')\n",
    "            \n",
    "    def explain(self, song):\n",
    "        \"\"\"\n",
    "        Explain the boost of a song\n",
    "        \n",
    "        Ignores the artist specific boost, which we cannot know beforehand\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        song: int or str\n",
    "            int: the index of the song in df\n",
    "            str: the title of the song (must be unique)\n",
    "        \"\"\"\n",
    "        song = self._get_song(song)\n",
    "        print('\\033[1m' + f\"{song.loc['Title']} by {song.loc['NameArtist']}\" + '\\033[0m')  # Using bold face\n",
    "        effects_artist = self._calculate_artist_effect(song)\n",
    "        total_artist_effect = np.prod(list(effects_artist.values()))\n",
    "        effects_song = self._calculate_song_effects(song)\n",
    "        self._print_effects(effects_artist)\n",
    "        print('-')\n",
    "        self._print_effects(effects_song, total_artist_effect)\n",
    "        print('')\n",
    "        print(f'The actual boost was {song.loc[\"BoostSong\"]:.2f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trala = b.all_effects(37989)\n",
    "trala['Diff'] = trala['TotalEffect'].diff()\n",
    "trala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trala = b.all_effects(15654)\n",
    "trala['Diff'] = trala['TotalEffect'].diff()\n",
    "trala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "mask_from = 2\n",
    "\n",
    "#Store data and create a blank series to use for the waterfall\n",
    "data = (b.all_effects(15654).assign(Diff = lambda df: df['TotalEffect'].diff().fillna(df['TotalEffect'])))\n",
    "data.iloc[mask_from:] = None\n",
    "blank = data['Diff'].cumsum().shift(1).fillna(0)\n",
    "\n",
    "#Get the net total number for the final element in the waterfall\n",
    "total = data['Diff'].sum()\n",
    "if mask_from is None:\n",
    "    \n",
    "    data.loc[\"Total\"] = total\n",
    "    blank.loc[\"Total\"] = total # This is only to get the steps right\n",
    "\n",
    "#The steps graphically show the levels as well as used for label placement\n",
    "step = blank.reset_index(drop=True).repeat(3).shift(-1)\n",
    "step[1::3] = np.nan\n",
    "if mask_from is None:\n",
    "    blank.loc[\"Total\"] = 0\n",
    "step.iloc[mask_from * 3:] = None\n",
    "\n",
    "\n",
    "#Plot and label\n",
    "my_plot = data['Diff'].plot(kind='bar', stacked=True, bottom=blank,legend=None, figsize=(20, 5))\n",
    "my_plot.plot(step.index, step.values,'k--')\n",
    "my_plot.set_xlabel(\"Transaction Types\")\n",
    "\n",
    "#Format the axis for dollars\n",
    "# my_plot.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "#Get the y-axis position for the labels\n",
    "y_height = trans['Diff'].cumsum().shift(1).fillna(0)\n",
    "\n",
    "#Get an offset so labels don't sit right on top of the bar\n",
    "max = trans['Diff'].max()\n",
    "neg_offset = max / 25\n",
    "pos_offset = max / 50\n",
    "plot_offset = max #/ 15\n",
    "\n",
    "#Start label loop\n",
    "loop = 0\n",
    "for index, row in data.iterrows():\n",
    "    # For the last item in the list, we don't want to double count\n",
    "    if row['Diff'] == total:\n",
    "        y = y_height[loop]\n",
    "    else:\n",
    "        y = y_height[loop] + row['Diff']\n",
    "    # Determine if we want a neg or pos offset\n",
    "    if row['Diff'] > 0:\n",
    "        y += pos_offset\n",
    "        va = 'bottom'\n",
    "    else:\n",
    "        y -= neg_offset\n",
    "        va = 'top'\n",
    "    my_plot.annotate(f'x {row[\"EffectSize\"]:.2f} \\n= {row[\"TotalEffect\"] : .2f}', (loop, y), ha=\"center\", va=va)\n",
    "#         my_plot.annotate(\"{:,.2f}\".format(row['Diff']),(loop,y),ha=\"center\")\n",
    "    loop+=1\n",
    "\n",
    "#Scale up the y axis so there is room for the labels\n",
    "my_plot.set_ylim(0, 1.2 * total)\n",
    "#Rotate the labels\n",
    "my_plot.set_xticklabels(trans.index, rotation=90)\n",
    "# plt.ylim(0, 5)\n",
    "plt.ylabel('Boost')\n",
    "# my_plot.get_figure().savefig(\"waterfall.png\",dpi=200,bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

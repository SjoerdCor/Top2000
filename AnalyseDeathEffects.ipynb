{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.preprocessing\n",
    "import sklearn.metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "\n",
    "import voteestimator\n",
    "import top2000analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = top2000analysis.AnalysisSetCreator()\n",
    "df_song = a.create_analysis_set('Data')\n",
    "df_artist = a.create_artist_set('Data')\n",
    "df = a.create_full_feature_set('Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist['Boost'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist.query('Boost < 1')[['Name', 'Boost', 'LogPopularityNorm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list = a._combine_data('Data')\n",
    "print(f\"In its history, the Top 2000 has seen {full_list['SongID'].nunique()} songs and {full_list['ArtistID'].nunique()} artists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_song['Boost'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_new_position(old_position, votesmodel, boost=1.75):\n",
    "    old_votes = votesmodel.percentage_of_votes(old_position)\n",
    "    new_votes = old_votes\n",
    "    new_position = old_position\n",
    "    while new_votes < boost * old_votes and new_position >= 1:\n",
    "        new_position -= 1\n",
    "        new_votes = votesmodel.percentage_of_votes(new_position)\n",
    "    return max(new_position, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positioning = (pd.DataFrame({'OldPosition': range(1, 2001)})\n",
    "               .assign(NewPosition = lambda df: [calculate_new_position(p, a.votesmodel) for p in df['OldPosition']],\n",
    "                      FactorRanking = lambda df: df['NewPosition'] / df['OldPosition']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positioning.plot(x='OldPosition', y='FactorRanking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create analysis set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate analysis\n",
    "* Newsworthyness of artist passing\n",
    "  * Age when passing away\n",
    "  * Dutch nationality\n",
    "  * Popularity\n",
    "  * Year\n",
    "  * Recency of hits\n",
    "* Days to stemperiode\n",
    "\n",
    "* Song\n",
    "  * Popularity within artist\n",
    "  * Recency of song within artist\n",
    "  \n",
    "### Newsworthyness\n",
    "\n",
    "#### Artist age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_trend(df, column, logy=False):\n",
    "    ycolname = 'LogBoost' if logy else 'Boost'\n",
    "    preds = LinearRegression().fit(df[[column]], df[ycolname]).predict(df[[column]])\n",
    "    ax = df.plot(x=column, y=ycolname, kind='scatter', label='Passed away artists', c='grey')\n",
    "    ax.plot(df[column], preds, 'k', label='Trend')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df_artist, 'AgePassing', logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jaar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df_artist, 'JaarTop2000', logy=False)\n",
    "ax.xaxis.set_major_locator(mtick.MaxNLocator(integer=True))\n",
    "ax.set_ylim(None, 6)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "ax.set_frame_on(False)\n",
    "plt.gcf().savefig('YearEffect.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.catplot(x='IsDutch', y='LogBoost', data=df_artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df_artist, 'PctVotes', logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_trend(df_artist, 'LogPopularity', logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = df_artist.assign(Popularity = lambda df: df['LogPopularity'].sub(df['LogPopularity'].median()),\n",
    "                            Boost = lambda df: df['Boost'])\n",
    "\n",
    "preds = LinearRegression().fit(dftest[['Popularity']], dftest['Boost']).predict(dftest[['Popularity']])\n",
    "ax = dftest.plot(x='Popularity', y='Boost', kind='scatter', c='grey', ylim=(None, 6))\n",
    "ax.plot(dftest[['Popularity']], preds, 'k', label='trend')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.gcf().savefig('PopularityEffect.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df_artist.query('DaysToStemperiode > -365'), 'DaysToStemperiode', logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recency_buckets = (pd.cut(df_artist['DaysToStemperiode'].clip(lower=-365), 6, labels=False, retbins=False, right=False)\n",
    "                  .map({i: v for i, v in enumerate(range(-333, 0, 60))}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist.groupby(recency_buckets)['LogBoost'].agg(['mean', 'sem', 'std', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_artist.groupby(recency_buckets)['LogBoost'].agg(['mean', 'sem', 'std', 'count']).plot(y='mean', yerr='sem')\n",
    "plt.xlim(-365, 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency of last hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df_artist, 'YearsSinceLastHit', logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(like='Nr').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SongRelativeBoost'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('NameArtist != \"André Hazes\" & NrsBeforeDeath > 1')['SongRelativeBoost'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nlargest(10, 'SongRelativeBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nsmallest(10, 'SongRelativeBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist['Boost'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('NameArtist != \"André Hazes\" & NrsBeforeDeath > 1')['SongRelativeBoost'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x='NrsBeforeDeath', y='SongRelativeBoost', data=df)\n",
    "ax.set_ylim(0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solo song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['NrArtists'])['LogBoost'].agg(['mean', 'std', 'sem', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['MultiplePerformers'])['LogBoost'].agg(['mean', 'std', 'sem', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity within artist oeuvre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df, 'PopularityWithinArtist', logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df, 'LogSongPopularityWithinArtist', logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency within artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df.query('NrsBeforeDeath > 2'), 'RecencyWithinArtist', logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waterfall(data, color=None, buildup=False, **kwargs):\n",
    "    '''\n",
    "    Plot a buildup or builddown waterfall chart from data\n",
    "    This function was adapted from https://pbpython.com/waterfall-chart.html\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: pd.Series to be shown as waterfall\n",
    "    color: optionally give color as a list for each bar (to highlight some bars)\n",
    "    buildup: False (default) for builddown, True for buildup\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ax: Axis object\n",
    "    data: the data, including a \"total\"-row\n",
    "    blank: the size of the blank space before each bar\n",
    "    '''\n",
    "    #TODO: add connecting lines\n",
    "    if color is None:\n",
    "        color = ['lightgray'] * len(data)\n",
    "\n",
    "    blank = data.cumsum().shift(1).fillna(0)\n",
    "    total = data.sum()\n",
    "    data.loc['Total'] = total\n",
    "    blank.loc['Total'] = 0\n",
    "    color = color + ['gray']\n",
    "    \n",
    "    step = blank.reset_index(drop=True).repeat(3).shift(-1)\n",
    "    step[1::3] = np.nan\n",
    "    \n",
    "    if buildup:\n",
    "        data = data[::-1]\n",
    "        blank = blank[::-1]\n",
    "        color = color[::-1]\n",
    "\n",
    "    ax = data.plot(kind='barh', stacked=True, left=blank, color=color, **kwargs)\n",
    "#     ax.plot(step.values, step.index, 'k--')\n",
    "\n",
    "    return ax, data, blank\n",
    "\n",
    "data = pd.cut(df_artist['Boost'], [0, 1, 1.25, 1.5, 2.5, np.inf],\n",
    "               labels=['No boost',\n",
    "                       'Up to 25% more votes',\n",
    "                       'Up to 50% more votes',\n",
    "                       '1.5 - 2.5 x\\nas many votes',\n",
    "                       'More than 2.5\\nx as many votes']).value_counts(normalize=True).sort_index(ascending=False)\n",
    "data.index = data.index.astype(str)\n",
    "ax, _, _ = plot_waterfall(data, color=['purple', 'purple', 'purple', 'purple', 'lightgray', 'gray'])\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1))\n",
    "ax.set_frame_on(False)\n",
    "plt.tight_layout()\n",
    "plt.gcf().savefig('BoostDistribution.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist.nlargest(10, 'Boost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist['Boost'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.drop_duplicates('NameArtist')['PassingTooEarly'] == 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "def model_factory(X, y):\n",
    "    passed_away_artists = X['ArtistID'].unique()\n",
    "    artist_lookup = dict(zip(passed_away_artists, range(len(passed_away_artists))))\n",
    "    artist_vals = X['ArtistID'].replace(artist_lookup).values\n",
    "    artist_model = (X.assign(ArtistIDModel = lambda df: X['ArtistID'].map(artist_lookup),\n",
    "                             )\n",
    "                .sort_values('ArtistIDModel')\n",
    "                .drop_duplicates(['ArtistIDModel'])\n",
    "               )\n",
    "    \n",
    "    \n",
    "    coords = {\"obs_id\": np.arange(X.shape[0]),\n",
    "              'Artist': range(len(passed_away_artists))\n",
    "         }\n",
    "    with pm.Model(coords=coords) as model:\n",
    "        artist_idx = pm.Data(\"artist_idx\", artist_vals, dims=\"obs_id\")\n",
    "        days_to_stemperiode = pm.Data('days_to_stemperiode', artist_model['DaysToStemperiode'], dims='Artist')\n",
    "        logpopularity = pm.Data('logpopularity', artist_model['LogPopularityNorm'], dims='Artist')\n",
    "        jaren_geleden = pm.Data(\"jaren_geleden\", artist_model['JarenGeleden'], dims='Artist')\n",
    "        passing_too_early = pm.Data('passing_too_early', artist_model['PassingTooEarly'], dims='Artist')\n",
    "        is_dutch = pm.Data('is_dutch', artist_model['IsDutchArtist'], dims='Artist')\n",
    "\n",
    "        multiple_performers = pm.Data('multiple_performers', X['MultiplePerformers'], dims=\"obs_id\")\n",
    "        popularity_within_oeuvre = pm.Data('popularity_within_oeuvre', X['LogSongPopularityWithinArtist'], dims=\"obs_id\")\n",
    "\n",
    "        # Hyperpriors:\n",
    "        a = pm.Normal(\"a\", mu=0, sigma=2.0)\n",
    "        sigma_a = pm.Exponential(\"sigma_a\", 1.0)\n",
    "\n",
    "        recency_effect_exponent = pm.Normal('recency_effect_exponent', mu=-1.5,sigma=1)\n",
    "        max_recency_effect = pm.Normal('max_recency_effect', mu=2, sigma=2)\n",
    "        effect_popularity = pm.Normal('effect_popularity', mu=0.5, sigma=2)\n",
    "        history_effect = pm.Normal('history_effect', mu=0, sigma=0.03)\n",
    "        age_passing_effect = pm.Normal('age_passing_effect', mu=0.01, sigma=0.05)\n",
    "        is_dutch_effect = pm.Normal('is_dutch_effect', mu=0, sigma=2)\n",
    "\n",
    "        # Expected value per artist:\n",
    "        mu_artist = (a\n",
    "                     + logpopularity * effect_popularity\n",
    "                     # The correction of subtracting the minimum value breaks the degeneracy between _a_ and the recency effect\n",
    "                     # It is important for two reasons:\n",
    "                     # 1. It makes sampling much more stable\n",
    "                     # 2. It allows for much easier interpretation of the recency effect\n",
    "                     + (np.exp(10**recency_effect_exponent * days_to_stemperiode)- np.exp(10**recency_effect_exponent * -365))* max_recency_effect\n",
    "                     + jaren_geleden * history_effect\n",
    "                     + passing_too_early * age_passing_effect\n",
    "                     + is_dutch * is_dutch_effect\n",
    "                    )\n",
    "\n",
    "        # This is the non-centered version of the model for a much more stable sampling\n",
    "        # See https://twiecki.io/blog/2017/02/08/bayesian-hierchical-non-centered/ for more information\n",
    "        # By making mu_artist and a_artist a pm.Deterministic, we can still access them via the InferenceData, but it is not strictly necessary\n",
    "        mu_artist = pm.Deterministic(\"mu_artist\", mu_artist, dims=\"Artist\")\n",
    "        za_artist = pm.Normal(\"za_artist\", mu=0.0, sigma=1.0, dims='Artist')\n",
    "        a_artist = pm.Deterministic(\"a_artist\", mu_artist + za_artist * sigma_a, dims=\"Artist\")\n",
    "        sharing_effect = pm.Normal('sharing_effect', mu=0, sigma=2.0)\n",
    "        within_oeuvre_effect = pm.Normal('within_oeuvre_effect', mu=0, sigma=2.0)\n",
    "        theta = (a_artist[artist_idx]\n",
    "                 + multiple_performers * sharing_effect\n",
    "                 + popularity_within_oeuvre * within_oeuvre_effect\n",
    "                )\n",
    "        # Model error:\n",
    "        sigma = pm.Exponential(\"sigma\", 1.0)\n",
    "\n",
    "        y_like = pm.Normal(\"y_like\", theta, sigma=sigma, observed=y, dims=\"obs_id\")\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_factory(X=df.drop(columns='LogBoost'),\n",
    "                   y=df['LogBoost'],\n",
    "                   ) as multilevel_noncentered_model:\n",
    "    display(pm.model_to_graphviz(multilevel_noncentered_model))\n",
    "    multilevel_noncentered_model_idata = pm.sample(10000, tune=3000, return_inferencedata=True, random_seed=RANDOM_SEED, target_accept=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(multilevel_noncentered_model_idata, var_names=['~za_artist', '~a_artist', '~mu_artist'], round_to=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.rcParams['plot.max_subplots'] = 100  # Since we have many parameters, the number of subplots is larger than the default - allow az to take more time plotting\n",
    "var_names = [\n",
    "            '~a_artist',\n",
    "            '~sigma_a',\n",
    "            '~sigma',\n",
    "            '~za_artist',\n",
    "            '~mu_artist'\n",
    "            ]\n",
    "_ = pm.pairplot(multilevel_noncentered_model_idata,\n",
    "                var_names=var_names, marginals=True,\n",
    "                divergences=True, kind=['scatter', 'kde'],\n",
    "                figsize=(30, 30), scatter_kwargs={'alpha': 0.06})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with multilevel_noncentered_model:\n",
    "    prior_checks = pm.sample_prior_predictive(random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_prior = az.from_dict(prior={k: v.T for k, v in prior_checks.items() if k != 'y_like'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilevel_noncentered_model_idata.extend(multi_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_dist_comparison(multilevel_noncentered_model_idata, var_names=['a', 'recency_effect_exponent', 'max_recency_effect',\n",
    "                                         'effect_popularity', 'history_effect', 'age_passing_effect',\n",
    "                                         'is_dutch_effect', 'sharing_effect', 'within_oeuvre_effect', 'sigma', 'sigma_a'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = az.plot_posterior(multilevel_noncentered_model_idata, ref_val=0, var_names=var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_autocorr(multilevel_noncentered_model_idata, var_names=var_names, combined=True, max_lag=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlations(df):\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax = sns.heatmap(df.corr(), cmap='RdBu_r', vmin=-0.8, vmax=0.8, annot=True, fmt='.1%', ax=ax, cbar=False)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes, artistnames = pd.factorize(df['NameArtist'])\n",
    "mapping = {c: a for c, a in zip(set(codes), artistnames)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_magic = multilevel_noncentered_model_idata.posterior.to_dataframe().groupby('Artist')['za_artist'].describe()\n",
    "artist_magic.index = artist_magic.index.map(mapping)\n",
    "artist_magic.sort_values('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = multilevel_noncentered_model_idata.posterior.to_dataframe().droplevel('Artist').loc[lambda x: ~x.index.duplicated()]\n",
    "plot_correlations(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with multilevel_noncentered_model:\n",
    "    ppc = pm.fast_sample_posterior_predictive(multilevel_noncentered_model_idata)\n",
    "    ppc_no_artist = pm.fast_sample_posterior_predictive(multilevel_noncentered_model_idata.posterior.drop_vars(['mu_artist', 'a_artist', 'za_artist']))\n",
    "    \n",
    "predictions = pd.DataFrame(ppc['y_like'].T, index=df.index)\n",
    "predictions_no_artist = pd.DataFrame(ppc_no_artist['y_like'].T, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE!! It only works with at least 2 different artists (which is far from perfect... but it is what it is)\n",
    "df_new_data = df.tail(2).copy()\n",
    "df_new_data['JarenGeleden'] = 100\n",
    "\n",
    "# Second comes the hold out data posterior predictive\n",
    "with model_factory(X=df_new_data,\n",
    "                   y=df_new_data['LogBoost'],\n",
    "                   ) as test_model:\n",
    "    # For newly passed artists, we do not know what za_artist should be\n",
    "    ppc_new_data = pm.fast_sample_posterior_predictive(multilevel_noncentered_model_idata.posterior.drop_vars(['mu_artist', 'a_artist', 'za_artist']),\n",
    "                                         var_names=['y_like'],\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the recency effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = {}\n",
    "days = np.arange(-365, 0)\n",
    "for i, row in parameters.iterrows():\n",
    "    recencyeffect = (np.exp(10**row['recency_effect_exponent'] * days) - np.exp(10**row['recency_effect_exponent'] * -365))* row['max_recency_effect']\n",
    "    outcomes[i] = recencyeffect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recencyeffect = pd.DataFrame(outcomes, index=np.arange(-365, 0)).apply(np.exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fig, ax = plt.subplots()\n",
    "df_recencyeffect.median(axis='columns').plot(ax=ax, lw=3, c='darkblue', label='Estimated effect')\n",
    "(df_artist.assign(RecencyEffect = lambda df: df['Boost']/df['Boost'].median())\n",
    "          .plot(x='DaysToStemperiode', y='RecencyEffect', kind='scatter', ax=ax, c='k', alpha=0.6, label='Passed away artists')\n",
    ")\n",
    "plt.legend()\n",
    "df_recencyeffect.sample(1500, axis='columns').plot(c='grey', alpha=0.01, legend=False, ax=ax)\n",
    "\n",
    "ax.set_xlabel('Days until end of voting')\n",
    "ax.set_ylabel('Extra boost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_date(days_from_date, reference_date='2020-12-07'):\n",
    "    return pd.Timestamp(reference_date) + pd.Series([pd.Timedelta(i, 'days') for i in days_from_date], index=days_from_date)\n",
    "\n",
    "ax =  (df_recencyeffect.median(axis='columns').to_frame()\n",
    "     .assign(Date = lambda df: convert_to_date(df.index))\n",
    "     .plot(x='Date', y=0, lw=3, c='darkblue', label='Estimated effect')\n",
    "    )\n",
    "\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b'))\n",
    "plt.ylabel('Extra boost')\n",
    "plt.xlabel('Date of passing')\n",
    "plt.yticks([1, 1.5, 2, 2.5])\n",
    "plt.savefig('recency_effect.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_to_use = [-365,\n",
    "               *list(range(-350, -50, 50)),\n",
    "               *list(range(-70, -10, 7)),\n",
    "               *list(range(-10, 0, 2)),\n",
    "              ]\n",
    "df_recencyeffect.quantile([0.025, 0.16, 0.5, 0.84, 0.975], axis='columns').loc[:, days_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding prediction quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = top2000analysis.BoostExplainer(parameters.median(), multilevel_noncentered_model_idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_agg = (pd.concat([predictions.quantile([0.16, 0.5, 0.84], axis='columns').transpose(), df['LogBoost']], axis='columns')\n",
    "                   .rename(columns={0.5: 'yhat'})\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ax = predictions_agg.plot(x='yhat', y='LogBoost', kind='scatter')\n",
    "valmin, valmax = predictions_agg[['LogBoost', 'yhat']].min().min(), predictions_agg[['LogBoost', 'yhat']].max().max()\n",
    "ax.plot([valmin, valmax], [valmin, valmax], 'k--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_exp = predictions_agg.apply(np.exp).rename(columns={'LogBoost': 'Boost'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_exp.sort_values('Boost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(predictions_exp['yhat'], predictions_exp['Boost'],\n",
    "             xerr=[predictions_exp['yhat'].sub(predictions_exp[0.16]), predictions_exp[0.84].sub(predictions_exp['yhat'])],\n",
    "             ls=' ', marker='o', alpha=0.6, ms=4)\n",
    "plt.gca().annotate('$\\it{Zij\\/gelooft\\/in\\/mij}$\\n by $\\it{André\\/Hazes}$', (2.123288,17.81695), (2.5, 14),\n",
    "                   arrowprops=dict(arrowstyle=\"->\", connectionstyle= \"angle3,angleA=0,angleB=90\"),\n",
    ")\n",
    "plt.plot([0, 8], [0, 8], 'k--')\n",
    "plt.ylabel('Boost in practice')\n",
    "plt.xlabel('Predicted boost')\n",
    "plt.savefig('Allboosts_compared.jpg')\n",
    "plt.show()\n",
    "plt.errorbar(predictions_exp['yhat'], predictions_exp['Boost'],\n",
    "             xerr=[predictions_exp['yhat'].sub(predictions_exp[0.16]), predictions_exp[0.84].sub(predictions_exp['yhat'])],\n",
    "             ls=' ', marker='o', alpha=0.2, ms=4)\n",
    "plt.plot([0, 11], [0, 11], 'k--')\n",
    "plt.ylabel('Boost in practice')\n",
    "plt.xlabel('Predicted boost')\n",
    "plt.ylim(0, 11.5)\n",
    "plt.xlim(0, 11.5)\n",
    "plt.savefig('boostcompared.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = (df\n",
    "              .assign(yhat = predictions.median(axis='columns'),\n",
    "                      error = lambda df: df['yhat'].sub(df['LogBoost']),\n",
    "                      abserror = lambda df: df['error'].abs(),\n",
    "                      yhat_no_artist = predictions_no_artist.median(axis='columns'),\n",
    "                      error_without_artisteffect = lambda df: df['yhat_no_artist'].sub(df['LogBoost']),\n",
    "                      abserror_without_artisteffect = lambda df: df['error_without_artisteffect'].abs(),\n",
    "                      improvement_artisteffect = lambda df: df['abserror_without_artisteffect'].sub(df['abserror']),\n",
    "                      yhat_median_params = lambda df: np.log([b.all_effects(i)['EffectSize'].prod() for i in range(len(df))]),\n",
    "                      error_median_params = lambda df: df['yhat_median_params'].sub(df['LogBoost']),\n",
    "                      abserror_median_params = lambda df: df['error_median_params'].abs(),\n",
    "                     )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior['improvement_artisteffect'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior[['LogBoost', 'yhat', 'yhat_no_artist', 'yhat_median_params']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior['LogBoost'].sub(posterior['LogBoost'].median()).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior['abserror'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior['abserror_without_artisteffect'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior['abserror_median_params'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior['abserror_median_params'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior['error_without_artisteffect'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior.nlargest(10, 'abserror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.concat(multilevel_noncentered_model_idata, \n",
    "          az.from_pymc3_predictions(ppc_new_data, model=test_model), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo_multilevel = az.loo(multilevel_noncentered_model_idata, pointwise=True)\n",
    "az.plot_khat(loo_multilevel, show_bins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding representative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['JarenGeleden',\n",
    "             'LogPopularityNorm',\n",
    "             'IsDutchArtist',\n",
    "             'PassingTooEarly',\n",
    "             'DaysEffect',\n",
    "             'LogSongPopularityWithinArtist',\n",
    "             'MultiplePerformers',          \n",
    "             'LogBoost']\n",
    "mm = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "all_data = (posterior\n",
    "            .assign(DaysEffect = lambda df: df_recencyeffect.median(axis='columns').loc[df['DaysToStemperiode'].clip(lower=-365)].tolist())\n",
    "            .filter(variables)\n",
    "            )\n",
    "mm.fit(all_data)\n",
    "\n",
    "data = (posterior\n",
    "        .query('abserror < 0.15 & LogPopularityNorm > -0.3 & DaysToStemperiode < -2')\n",
    "        .assign(DaysEffect = lambda df: df_recencyeffect.median(axis='columns').loc[df['DaysToStemperiode'].clip(lower=-365)].tolist())\n",
    "        .filter(variables)\n",
    "        .drop(\n",
    "        [10036, # Never be clever is technically performed also by Herman Broods band, but it's considered to be performed by a single artist\n",
    "        ]\n",
    "        )\n",
    "       )\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = mm.transform(data)\n",
    "dists = sklearn.metrics.pairwise_distances(normalized_data, metric='minkowski', p=1)\n",
    "inds = np.argsort(dists, axis=None)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_effects = ['LogBoost', 'yhat', 'error','yhat_no_artist', 'error_without_artisteffect']\n",
    "variables = [v for v in variables if v != 'DaysEffect']\n",
    "# Use step size of 2 because of symmetry: each pair is present twice\n",
    "for ind in inds[:10:2]:\n",
    "    x, y = divmod(ind, len(data))\n",
    "    print(f'Distance: {dists[x, y]:.3f}; ({x}, {y})')\n",
    "    ind = data.iloc[[x, y]].index\n",
    "\n",
    "    new_df = pd.concat([df.assign(pos = range(len(df)))[['NameSong', 'Title', 'LogBoost', 'BoostSong', 'DaysToStemperiode', 'pos'] + variables],\n",
    "                        posterior[boosting_effects]], axis='columns')\n",
    "    display(new_df.loc[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figuring out the boost for two songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, include_difference):\n",
    "    df = df.assign(TotalEffect = lambda df: df['EffectSize'].cumprod(),\n",
    "                   Diff = lambda df: df['TotalEffect'].diff().fillna(df['TotalEffect']))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_colours(data, mask_from, including_difference):\n",
    "    if mask_from is None:\n",
    "        if including_difference:\n",
    "            c = ['gray'] + (len(data) - 4) * ['lightgray'] + ['purple', 'red', 'purple']\n",
    "            return c\n",
    "        else:\n",
    "            mask_from = len(data)\n",
    "    if mask_from == 1:\n",
    "        c =  ['purple']\n",
    "    elif mask_from <= len(data):\n",
    "        c = ['gray'] + (mask_from - 2) * ['lightgray'] + ['purple']\n",
    "    return c\n",
    "    \n",
    "def plot_waterfall(effects, mask_from, including_difference=False, ax=None, horizontal=False):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    data = effects.copy()\n",
    "    #Store data and create a blank series to use for the waterfall\n",
    "    total = data['Diff'].sum()\n",
    "\n",
    "    if mask_from is not None:\n",
    "        data.iloc[mask_from:] = None\n",
    "    blank = data['Diff'].cumsum().shift(1).fillna(0)\n",
    "\n",
    "    #Get the net total number for the final element in the waterfall\n",
    "    if mask_from is None:\n",
    "        data.loc[(\"Total\", ''), 'EffectSize'] = 1\n",
    "        data.loc[(\"Total\", ''), 'Diff'] = total\n",
    "        data.loc[(\"Total\", ''), 'TotalEffect'] = total\n",
    "        blank.loc[\"Total\"] = total # This is only to get the steps right - it will later correctly be set to 0\n",
    "\n",
    "    #The steps graphically show the levels as well as used for label placement\n",
    "    step = blank.reset_index(drop=True).repeat(3).shift(-1)\n",
    "    step[1::3] = np.nan\n",
    "    if mask_from is None:\n",
    "        blank.loc[\"Total\"] = 0\n",
    "    else:\n",
    "        step.iloc[mask_from * 3:] = None\n",
    "    \n",
    "    if including_difference:\n",
    "        blank.loc[('Prediction', '')] = 0\n",
    "        data.loc[('Prediction', ''), 'Diff'] = data.loc[('Prediction', ''), 'TotalEffect']\n",
    "\n",
    "    #Plot and label\n",
    "    colours = find_colours(data, mask_from, including_difference)\n",
    "    kind = 'bar' if not horizontal else 'barh'\n",
    "    ax = data['Diff'].plot(kind=kind,\n",
    "                           stacked=True,\n",
    "                           bottom=blank,\n",
    "                           left=blank,\n",
    "                           legend=None,\n",
    "                           color=colours,\n",
    "                           ax=ax)\n",
    "    if horizontal:\n",
    "        ax.plot(step.values, step.index,'k', linewidth=1)\n",
    "    else:\n",
    "        ax.plot(step.index, step.values,'k', linewidth=1)\n",
    "\n",
    "    #Get the y-axis position for the labels\n",
    "    y_height = data['Diff'].cumsum().shift(1).fillna(0)\n",
    "\n",
    "    #Get an offset so labels don't sit right on top of the bar\n",
    "    neg_offset = max / 25\n",
    "    pos_offset = max / 50\n",
    "    \n",
    "    #Start label loop\n",
    "    loop = 0\n",
    "    for index, row in data.iterrows():\n",
    "        # For the last item in the list, we don't want to double count\n",
    "        y = row['TotalEffect']\n",
    "        # Determine if we want a neg or pos offset\n",
    "        if row['Diff'] >= 0:\n",
    "            y += pos_offset\n",
    "            va = 'bottom'\n",
    "            ha = 'left'\n",
    "        else:\n",
    "            y -= neg_offset\n",
    "            va = 'top'\n",
    "            ha = 'right'\n",
    "        if index not in [('Prediction', ''), ('Total', '')]:\n",
    "            label = f'x {row[\"EffectSize\"]:.2f}'\n",
    "        else:\n",
    "            label = ''\n",
    "        if loop > 0:\n",
    "            label += f'\\n= {row[\"TotalEffect\"] : .2f}'\n",
    "        if horizontal:\n",
    "            ax.annotate(label, (y, loop), va=\"center\", ha=ha, fontsize=11)\n",
    "        else:\n",
    "            ax.annotate(label, (loop, y), ha=\"center\", va=va, fontsize=11)\n",
    "        loop += 1\n",
    "\n",
    "    #Scale up the axis so there is room for the labels\n",
    "    if horizontal:\n",
    "        ax.axvline(1, c='k', ls='--')\n",
    "        ax.set_xlim(0, 3)\n",
    "    else:\n",
    "        ax.axhline(1, c='k', ls='--')\n",
    "        ax.set_ylim(0, 3)\n",
    "    \n",
    "    labels = ['Base',\n",
    "                'Historical\\neffect',\n",
    "                'Popularity\\neffect',\n",
    "                'Artist is\\nDutch',\n",
    "                'Artist\\ndied young',\n",
    "                'Timing of\\ndeath',\n",
    "                'Artist\\ndeviation',\n",
    "                'Song popularity\\nwithin artist oeuvre',\n",
    "                'Multiple\\nperformers',\n",
    "                'Prediction'\n",
    "                ]\n",
    "    if including_difference:\n",
    "        labels += ['Difference from\\nactual boost', 'Actual boost']\n",
    "    if horizontal:\n",
    "        ax.set_yticklabels(labels)\n",
    "        ax.invert_yaxis()\n",
    "    else:\n",
    "        ax.set_xticklabels(labels)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    if horizontal:\n",
    "        ax.set_xlabel('Boost', fontsize=14)\n",
    "        ax.set_ylabel('Effects', fontsize=14)\n",
    "    else:\n",
    "        ax.set_ylabel('Boost', fontsize=14)\n",
    "        ax.set_xlabel('Effects', fontsize=14)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_placement(series):\n",
    "    result = {'absolute': series.rank(pct=False, ascending=False).astype(int),\n",
    "             'percent': series.rank(pct=True, ascending=False)}\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "full_list['PctVotes'] = full_list['Rank'].apply(voteestimator.MeindertsmaVotesEstimator().percentage_of_votes)\n",
    "votes_per_artist_per_year = full_list.groupby(['Name', 'Year'])[['PctVotes']].sum()\n",
    "votes_per_artist_per_year.groupby('Year')['PctVotes'].apply(calculate_placement).loc[[('David Bowie', 2015), ('André Hazes', 2003)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus = None\n",
    "song_pos = 76\n",
    "explanation = b.all_effects(song_pos)\n",
    "data_eenzamekerst = explanation.pipe(preprocess, False)\n",
    "data_eenzamekerst_incl_diff = b.all_effects(song_pos, True, multilevel_noncentered_model_idata).pipe(preprocess, True)\n",
    "\n",
    "song_pos = 1\n",
    "explanation = b.all_effects(song_pos)\n",
    "data_underpressure = explanation.pipe(preprocess, False)\n",
    "data_underpressure_incl_diff = b.all_effects(song_pos, True, multilevel_noncentered_model_idata).pipe(preprocess, True)\n",
    "\n",
    "fig, subplots = plt.subplots(1, 2, figsize=(11, 7))\n",
    "ax = plot_waterfall(data_eenzamekerst_incl_diff, focus, True, subplots[0], True)\n",
    "ax.set_title('Eenzame Kerst by André Hazes')\n",
    "plt.setp(ax.get_xticklabels()[-1], visible=False)\n",
    "\n",
    "ax2 = plot_waterfall(data_underpressure_incl_diff, focus, True, subplots[1], True)\n",
    "ax2.set_title('Under Pressure by David Bowie & Queen')\n",
    "ax2.set_yticklabels([])\n",
    "ax2.set_ylabel('')\n",
    "plt.setp(ax2.get_xticklabels()[0], visible=False)\n",
    "plt.subplots_adjust(wspace=1e-2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'EffectsEKUP_incl_diff_horizontal.jpg')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 7))\n",
    "plot_waterfall(data_eenzamekerst, 1, False, horizontal=True, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'Effects_base_horizontal.jpg')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for focus in list(range(2, len(data_eenzamekerst) + 1)) + [None]:\n",
    "    fig, subplots = plt.subplots(1, 2, figsize=(11, 7))\n",
    "    \n",
    "    ax = plot_waterfall(data_eenzamekerst, focus, False, subplots[0], True)\n",
    "    ax.set_title('Eenzame Kerst by André Hazes')\n",
    "    plt.setp(ax.get_xticklabels()[-1], visible=False)\n",
    "\n",
    "    ax2 = plot_waterfall(data_underpressure, focus, False, subplots[1], True)\n",
    "    ax2.set_title('Under Pressure by David Bowie & Queen')\n",
    "    ax2.set_yticklabels([])\n",
    "    ax2.set_ylabel('')\n",
    "    plt.setp(ax2.get_xticklabels()[0], visible=False)\n",
    "    \n",
    "    plt.subplots_adjust(wspace=1e-2)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'EffectsEKUP_focus_{focus}_horizontal.jpg')\n",
    "    plt.close(fig) # Do not show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

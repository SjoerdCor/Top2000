{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.preprocessing\n",
    "import sklearn.metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "import top2000analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_OUTPUT = os.path.join('..', 'Output')\n",
    "FOLDER_DATA = os.path.join('..', 'Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently, I published a [blog](https://sjoerdcornelissen.com/2021/03/02/the-effect-of-passing-away-on-top-2000-ranking/.) on the effect of passing away on rakings in the Top 2000. In this blog series, I will show how I built all the steps.\n",
    "\n",
    "I will do so in three parts:\n",
    "1. Part 1: Reading and understanding the data\n",
    "1. Part 2: Building and checking a hierarchical Bayesian regresson model\n",
    "1. Part 3: Using the model for inference and prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS NOTEBOOK IS STILL UNDER CONSTRUCTION AND WILL BE UPDATED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and inspect the Top 2000 data \n",
    "## Scraping the data\n",
    "First, we scrape all the data from wikipedia. This is done in the `readtop2000` module. It does so in 4 steps:\n",
    "1. Scrape the full list from https://nl.wikipedia.org/wiki/Lijst_van_Radio_2-Top_2000%27s\n",
    "1. Split into a data model, which contains 4 tables:\n",
    "\n",
    "    a. All unique songs\n",
    "    \n",
    "    b. All unique artists\n",
    "    \n",
    "    c. The ranking of each song in each year\n",
    "    \n",
    "    d. The artist(s) who performed each song\n",
    "1. For each artist, visit their personal wikipedia page and download all data from the infobox\n",
    "\n",
    "1. Finally, save all the data in the Data folder\n",
    "\n",
    "Since we only need to do this once, the lines below are commented out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import readtop2000\n",
    "# readtop2000.Top2000Downloader().download_and_write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recombining and selecting the data\n",
    "Now, we wish to get a table on which we can perform the analysis. For this, we combine all data, with one row for each artist for each song, so a song which is a duet occurs twice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = top2000analysis.AnalysisSetCreator()\n",
    "\n",
    "df_full = a._combine_data(FOLDER_DATA)\n",
    "print(f\"In its history, the Top 2000 has seen {df_full['SongID'].nunique()} unique songs and {df_full['ArtistID'].nunique()} unique artists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our analysis, we only select the rows of the years in which the artist passed away, and add the information of the year before, so we can compare the number of votes.\n",
    "\n",
    "We also calculate the percentage of the vote each song received every year based on a model from [Peter Meindertsma](https://www.petermeindertsma.nl/blog/benadering-aantal-stemmen-per-liedje-in-de-top-2000-van-2014/). We end up with the dataframe as shown below, which contains all the information we need to perform the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist = a.create_artist_set(FOLDER_DATA)\n",
    "df = a.create_full_feature_set(FOLDER_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The final data contains {len(df)} rows, which means there are {len(df)} songs which were in the Top 2000 the year before the artist passed away.')\n",
    "print(f'They come from {df[\"ArtistID\"].nunique()} unique artists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df['Year'].value_counts().sort_index().plot(ylim=(0, None), xlabel='Year', ylabel='Nr of artists\\nwho passed away')\n",
    "ax.xaxis.set_major_locator(mtick.MaxNLocator(integer=True))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a number of artists passing awayt each year, with a spike in 2016.\n",
    "\n",
    "Next, let's see what happened to the ranking of each song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = (df_full\n",
    "         .pipe(a._rank_features) # Necessary for _song_features\n",
    "         .pipe(a._song_features) # Calculates the years since overlijden; to find the year before and year of passing away\n",
    "         .query('-1 <= YearsSinceOverlijden <= 0')\n",
    "         .loc[lambda df: df.groupby('SongID')['YearsSinceOverlijden'].transform('count') == 2]\n",
    "         .set_index(['SongID', 'YearsSinceOverlijden'])['Rank']\n",
    "         .unstack()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = ranks.plot(kind='scatter', x=0, y=-1, label='Song of artist who passed away')\n",
    "ax.plot([0, 2000], [0, 2000], 'k--', label='Position last year')\n",
    "ax.set_xlabel('Ranking before passing away')\n",
    "ax.set_ylabel('Ranking in year of passing away')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most dots are below the dashed line, indeed almost all songs (but notably not all) receive some sort of boost in the year the artist passed away. We also see there are huge differences in the size of the effect: with some songs ranking below 1500 entering the Top 250 a year later, while some Top 500 songs stay right where they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the analysis, the discrete nature of rankings is a problem; the difference between songs ranked 2000 and 1980 is very different from the songs ranked 21st and first. Therefore, we estimate the number of votes through a model developed by [Peter Meindertsma](https://www.petermeindertsma.nl/blog/benadering-aantal-stemmen-per-liedje-in-de-top-2000-van-2014/).\n",
    "Furthermore, we define a _Boost_  as the ratio between the percentage of votes of the song in the year of the artist passing away and the percentage of the vote of that song in the year before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(series, dist='norm', **kwargs):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    series.plot(kind='kde', ax=axes[0], **kwargs)\n",
    "    scipy.stats.probplot(series, dist=dist, plot=axes[1])\n",
    "    plt.show()\n",
    "    display(series.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df['BoostSong'], xlim=(0, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the average song gets a boost of 2.3x as many votes as the year before, and the median is 1.75x as many votes. Notably, the Boost distrution is not Normal. Therefore, we also inspect the logarithm of the boost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df['LogBoost'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not perfectly normal, but much better. In our further estimation, we will often work with the logarithm, because the regular boost is dominated by a few outliers.\n",
    "\n",
    "Next, we will also investigate the _artist boost_, defined as the the total number of votes for an artist in the year of his death divided by the total number of votes in the year before, instead of each song individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(df_artist['Boost'], xlim=(0, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we see the same distribution. Notably, the average _artist_ boost is lower than the average _song_ boost. This can be explained if artists with multiple songs on average see a larger boost. We make the same plot, but now binned for easier interpretation, to show in the blog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_waterfall(data, color=None, buildup=False, **kwargs):\n",
    "    '''\n",
    "    Plot a buildup or builddown waterfall chart from data\n",
    "    This function was adapted from https://pbpython.com/waterfall-chart.html\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: pd.Series to be shown as waterfall\n",
    "    color: optionally give color as a list for each bar (to highlight some bars)\n",
    "    buildup: False (default) for builddown, True for buildup\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ax: Axis object\n",
    "    data: the data, including a \"total\"-row\n",
    "    blank: the size of the blank space before each bar\n",
    "    '''\n",
    "    if color is None:\n",
    "        color = ['lightgray'] * len(data)\n",
    "\n",
    "    blank = data.cumsum().shift(1).fillna(0)\n",
    "    total = data.sum()\n",
    "    data.loc['Total'] = total\n",
    "    blank.loc['Total'] = 0\n",
    "    color = color + ['gray']\n",
    "    \n",
    "    step = blank.reset_index(drop=True).repeat(3).shift(-1)\n",
    "    step[1::3] = np.nan\n",
    "    \n",
    "    if buildup:\n",
    "        data = data[::-1]\n",
    "        blank = blank[::-1]\n",
    "        color = color[::-1]\n",
    "\n",
    "    ax = data.plot(kind='barh', stacked=True, left=blank, color=color, **kwargs)\n",
    "    return ax, data, blank\n",
    "\n",
    "data = pd.cut(df_artist['Boost'], [0, 1, 1.25, 1.5, 2.5, np.inf],\n",
    "               labels=['No boost',\n",
    "                       'Up to 25% more votes',\n",
    "                       'Up to 50% more votes',\n",
    "                       '1.5 - 2.5 x\\nas many votes',\n",
    "                       'More than 2.5\\nx as many votes']).value_counts(normalize=True).sort_index(ascending=False)\n",
    "data.index = data.index.astype(str)\n",
    "ax, _, _ = plot_waterfall(data, color=['purple', 'purple', 'purple', 'purple', 'lightgray', 'gray'])\n",
    "ax.set_ylabel('Effect size')\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1))\n",
    "ax.set_frame_on(False)\n",
    "plt.tight_layout()\n",
    "plt.gcf().savefig(os.path.join(FOLDER_OUTPUT,'BoostDistribution.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check who got the smallest and largest boosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_artist.query('Boost < 1')[['Name', 'Boost', 'LogPopularityNorm']].sort_values('Boost'))\n",
    "display(df_artist.nlargest(10, 'Boost')[['Name', 'Boost', 'LogPopularityNorm']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate analysis\n",
    "\n",
    "To get a first feeling for the data, formulate hypotheses on what affects the size of the boost on three levels:\n",
    "1. A __base__ effect for every artist\n",
    "1. An __artist specific__ effect, based on the characteristics of the artist and his/her death - aspects that have to do with how prominent the artist will be in the news after his/her death\n",
    "1. A __song specific__ effect, for which songs channel the newfound votes.\n",
    "\n",
    "For each step, the hypotheses are shown in the table below:\n",
    "\n",
    "<img src=\"../blogfigures/Hypothesis.png\" alt=\"Hypotheses are formulated for each level, to predict the boost of a song\" width=\"750\"/>\n",
    "\n",
    "In this section, we want to get a first look into the univariate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we dive in, lets check the relative importance of the levels. For this, we look into artist who have multiple songs, and compare the explained variance score for the song boost as explained by the _artist_ boost on the one hand, and the _Relative Song_ boost (the boost of the song divided by the artist boost) on the other hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multiple_songs = df.query('NrsBeforeDeath >= 2')\n",
    "print(f'There are {len(df_multiple_songs)} songs by artists with at least two songs')\n",
    "artist_variance = sklearn.metrics.explained_variance_score(df_multiple_songs['LogBoost'], np.log(df_multiple_songs['BoostArtist']))\n",
    "song_variance = sklearn.metrics.explained_variance_score(df_multiple_songs['LogBoost'], df_multiple_songs['LogRelativeBoost'])\n",
    "print(f'The explained variance of the artist is {artist_variance: .1%}')\n",
    "print(f'The explained variance of the relative song boost is {song_variance: .1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x='NrsBeforeDeath', y='SongRelativeBoost', data=df)\n",
    "ax.set_ylim(0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The artist is most important, but we also see there is definetly still a lot of variance within the songs of an artist, which we should try to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_trend(df, column, logy=False):\n",
    "    ycolname = 'LogBoost' if logy else 'Boost'\n",
    "    preds = LinearRegression().fit(df[[column]], df[ycolname]).predict(df[[column]])\n",
    "    ax = df.plot(x=column, y=ycolname, kind='scatter', label='Passed away artists', c='grey')\n",
    "    ax.plot(df[column], preds, 'k', label='Trend')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist level\n",
    "\n",
    "### Artist age\n",
    "Newsworthiness of the death of an artist depends on the circumstances. Specifically, artists dying young is something that attracts a lot of media attention. This happens a lot in our sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_dying_before_80 = df_artist['AgePassing'].lt(80).mean()\n",
    "print(f'{pct_dying_before_80:.1%} of the artists who passed away were younger than 80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df_artist, 'AgePassing', logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not see a strong _univariate_ effect, but this may be because of collinearity with other effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaar\n",
    "We hypothesize the boost has grown stronger over the years, because of more prevalent news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df_artist, 'JaarTop2000', logy=True)\n",
    "ax.xaxis.set_major_locator(mtick.MaxNLocator(integer=True))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "ax.set_frame_on(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nationality\n",
    "We hypothesize Dutch voters care more about Dutch artists, out of chauvinism. The effect is hard to detect, since only a small number of Dutch artists passed away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{df_artist[\"IsDutch\"].sum()} Dutch artists passed away')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.catplot(x='IsDutch', y='LogBoost', data=df_artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity\n",
    "When more popular artists die, they get much more news coverage: a relatively unknown artist may get a small article on page 15, while superstars may get entire TV shows devoted to hem. This in turn would result in much more prominent boosts for more popular artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df_artist, 'PctVotes', logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be the case, but the effect between the _logarithm_  of the boost and the percentage of the votes is clearly non-linear, and the trendline is dominated by a few superstars. Let's look into the logarith of the percentage of votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_trend(df_artist, 'LogPopularity', logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much better: there is a strong, mostly linear relation between the logarith of the boost and the logarithm of the popularity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency\n",
    "We hypothesize that the more top of mind a death is, the more of a boost an artist can expect - so more recent deaths during the time of voting should get a larger boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df_artist.query('DaysToStemperiode > -365'), 'DaysToStemperiode', logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, this is the case; however, it is not entirely clear if this is a linear relationship. Lets bucket the observations to see that clearer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recency_buckets = (pd.cut(df_artist['DaysToStemperiode'].clip(lower=-365), 6, labels=False, retbins=False, right=False)\n",
    "                  .map({i: v for i, v in enumerate(range(-333, 0, 60))}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist.groupby(recency_buckets)['LogBoost'].agg(['mean', 'sem', 'std', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_artist.groupby(recency_buckets)['LogBoost'].agg(['mean', 'sem', 'std', 'count']).plot(y='mean', yerr='sem')\n",
    "plt.xlim(-365, 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be little difference out to ~ 150 days, and then the boost grows much stronger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency of last hit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, there might be an effect whether artists were recently popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df_artist, 'YearsSinceLastHit', logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that, probably mostly by coincidence, in recent years artists in the Top 2000 have tended to pass away at later ages, which may partly explain why we do not see a strong age effect in a univariate distribution. Furthermore, we see that in recent years more popular artists have tended to pass away, which may spuri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlations(df, figsize=(12, 12)):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax = sns.heatmap(df.corr(), cmap='RdBu_r', vmin=-0.8, vmax=0.8, annot=True, fmt='.1%', ax=ax, cbar=False)\n",
    "    return ax\n",
    "\n",
    "plot_correlations(df_artist[['AgePassing', 'JaarTop2000', 'DaysToStemperiode', 'LogPopularity', 'IsDutch']], figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solo song\n",
    "We hypothesize that solo songs get more of a boost than duets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['NrArtists'])['LogBoost'].agg(['mean', 'std', 'sem', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only one song that has more than 2 performers (namely, _Laat me/Vivre_ by Alderliefste, Liesbeth List and Ramses Shaffy; the latter two have passed away during the Top 2000), so let's group that together, since the errors are huge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.groupby(['MultiplePerformers'])['LogBoost'].agg(['mean', 'std', 'sem', 'count']))\n",
    "(df.groupby(['MultiplePerformers'])\n",
    " ['LogBoost'].agg(['mean', 'std', 'sem', 'count'])\n",
    " .plot(y='mean', yerr='sem',\n",
    "       xlim=(-0.5, 1.5), kind='bar')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are not a lot of duets, but there is a hint they may indeed have a smaller boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity within artist oeuvre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [literature](https://link.springer.com/article/10.1007/s11002-014-9322-1) there is some work that shows more popular albums get larger boosts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df, 'PopularityWithinArtist', logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not see that effect very strongly, but again, we are dominated by a few outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df, 'LogSongPopularityWithinArtist', logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, there appears to be a contrary effect. This may be explained, however, by a) our assumptions of the voting distribution and/or b) collinearity with other effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency within artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hypothesize the more recent work may receive more of a boost, since the older work may be somewhat forgotten by now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_with_trend(df.query('NrsBeforeDeath > 2'), 'RecencyWithinArtist', logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not see that effect."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Top2000H",
   "language": "python",
   "name": "top2000h"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
